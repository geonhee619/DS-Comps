{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce DataFrame Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "    from pandas.api.types import is_categorical_dtype\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelize DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_parallelize_run(df, func):\n",
    "    import multiprocessing\n",
    "    num_partitions, num_cores = psutil.cpu_count(), psutil.cpu_count()\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Related (Categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_concat(df, subject_cols, print_option=True):\n",
    "    na_col = list(df.columns[df.isna().any()])\n",
    "    for col in na_col:\n",
    "        df[col].fillna('', inplace=True)\n",
    "    temp_str = ''\n",
    "    for col in subject_cols:\n",
    "        temp_str += '_' + col\n",
    "    df[temp_str[1:]] = ''\n",
    "    for col in subject_cols:\n",
    "        df[temp_str[1:]] += df[col]\n",
    "    \n",
    "    if print_option:\n",
    "        print(\"Generated features: category_concat\")\n",
    "        print(f\"'{temp_str[1:]}',\")\n",
    "        print()\n",
    "    del na_col, temp_str, col; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cat_MEAN',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>cat_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat  label  cat_MEAN\n",
       "0    a      1      0.75\n",
       "1    a      1      0.75\n",
       "2    a      1      0.75\n",
       "3    a      0      0.75\n",
       "4    b      1      0.50\n",
       "5    b      1      0.50\n",
       "6    b      0      0.50\n",
       "7    b      0      0.50\n",
       "8    c      1      0.25\n",
       "9    c      0      0.25\n",
       "10   c      0      0.25\n",
       "11   c      0      0.25"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class apply_target_encode:\n",
    "    #def __init__(self, target_col, cat_col):\n",
    "    #    self.target_col = target_col\n",
    "    #    self.cat_col = cat_col\n",
    "    \n",
    "    # (for train/train in oof_te)\n",
    "    # fit grouped label stats of given df\n",
    "    def fit_train(df, target_col, cat_col, m=0, statistic=False):\n",
    "        # df[target_col] = np.log1p(df[target_col])\n",
    "        df_group = df.groupby(cat_col)[target_col]\n",
    "        group_mean = df_group.mean().astype(np.float16)\n",
    "        temp_stat = []\n",
    "\n",
    "        # ===== smoothing =====\n",
    "        if m > 0:\n",
    "            global_mean = df[target_col].mean()\n",
    "            group_count = df_group.count().astype(np.float16)\n",
    "            smoother = ((group_count * group_mean) + (m * global_mean)) / (group_count + m)\n",
    "            temp_mean = (smoother, f'SMTH_MEAN_{m}')\n",
    "\n",
    "        # ===== no smoothing =====\n",
    "        elif m == 0:\n",
    "            temp_mean = (group_mean, 'MEAN')\n",
    "\n",
    "        # ===== more target statistic =====\n",
    "        if statistic:\n",
    "            group_min = df_group.min().astype(np.float16)\n",
    "            group_max = df_group.max().astype(np.float16)\n",
    "            group_std = df_group.std().astype(np.float16)\n",
    "            group_rng = group_max - group_min\n",
    "            group_Q1 = df_group.quantile(0.25).astype(np.float16)\n",
    "            group_Q2 = df_group.median().astype(np.float16)\n",
    "            group_Q3 = df_group.quantile(0.75).astype(np.float16)\n",
    "            group_IQR = group_Q3 - group_Q1\n",
    "            temp_stat = [(group_max, 'MAX'), (group_min, 'MIN'),\n",
    "                         (group_rng, 'RNG'), (group_std, 'STD'),\n",
    "                         (group_Q1, 'Q1'), (group_Q2, 'Q2'),\n",
    "                         (group_Q3, 'Q3'), (group_IQR, 'IQR')]\n",
    "\n",
    "        temp_stat.append(temp_mean)\n",
    "        return temp_stat\n",
    "    \n",
    "    # (for train/valid in oof_te)\n",
    "    # transform (encode) given df via given grouped label stats from fit_train\n",
    "    def transform_valid(temp_stat, df, cat_col, print_option=True):\n",
    "        for mapper, agg_str in temp_stat:\n",
    "            df[f'{cat_col}_{agg_str}'] = df[f'{cat_col}'].map(mapper)\n",
    "            if print_option:\n",
    "                print(f\"'{cat_col}_{agg_str}',\")\n",
    "    \n",
    "    # (for ordinary use or test in oof_te)\n",
    "    # fit_train and tranform_valid combined\n",
    "    def fit_transform(df, test_df, target_col, cat_col, m=0, statistic=False, print_option=True):\n",
    "        temp_stat = apply_target_encode.fit_train(df, target_col, cat_col, m, statistic)\n",
    "        for mapper, agg_str in temp_stat:\n",
    "            df[f'{cat_col}_{agg_str}'] = df[f'{cat_col}'].map(mapper)\n",
    "            test_df[f'{cat_col}_{agg_str}'] = test_df[f'{cat_col}'].map(mapper)\n",
    "            if print_option:\n",
    "                print(f\"'{cat_col}_{agg_str}',\")\n",
    "    \n",
    "    # train/train: fit grouped label statistic (with fit_train)\n",
    "    # train/valid: encode via the fitted (with transform_valid)\n",
    "    # test: fit with entire train, encode to test\n",
    "    # note: smoothing is universally applied.\n",
    "    # for diff m, utilize each function flexibly\n",
    "\n",
    "def oof_te(df, test_df, target_col, cat_col, split, m=0, statistic=False, print_option=True):\n",
    "    # train oof target encode\n",
    "    for train_idx, valid_idx in split:\n",
    "        temp_stat = apply_target_encode.fit_train(df=df.loc[train_idx, :],\n",
    "                                                  target_col=target_col,\n",
    "                                                  cat_col=cat_col,\n",
    "                                                  m=m,\n",
    "                                                  statistic=statistic)\n",
    "        apply_target_encode.transform_valid(temp_stat=temp_stat,\n",
    "                                            df=df.loc[valid_idx, :],\n",
    "                                            cat_col=cat_col,\n",
    "                                            print_option=False)\n",
    "\n",
    "    # test oof (=train) target encode\n",
    "    apply_target_encode.fit_transform(df=df,\n",
    "                                      test_df=test_df,\n",
    "                                      target_col=target_col,\n",
    "                                      cat_col=cat_col,\n",
    "                                      m=m,\n",
    "                                      statistic=statistic,\n",
    "                                      print_option=print_option)\n",
    "    return df\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "x_tr = pd.DataFrame(np.array([['a','a','a','a','b','b','b','b','c','c','c','c',],[1,1,1,0,1,1,0,0,1,0,0,0,]]).transpose(), columns=['cat', 'label'])\n",
    "x_tr['label'] = x_tr.label.astype(np.int8)\n",
    "x_te = pd.DataFrame(['a', 'a', 'b', 'b', 'c'], columns=['cat'])\n",
    "cv = [[[0,1,4,5,8,9],[2,3,7,8,10]],[[2,3,7,8,10],[0,1,4,5,8,9]]]\n",
    "oof_te(x_tr, x_te, 'label', 'cat', split=cv, m=0, statistic=False, print_option=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for fold, (train_idx, valid_idx) in enumerate(cv):\n",
    "    print(fold)\n",
    "    print(x_tr.loc[train_idx,:])\n",
    "    print(x_tr.loc[valid_idx,:])\n",
    "\n",
    "    temp_stat = apply_target_encode.fit_train(df=x_tr.loc[train_idx, :],\n",
    "                                                      target_col='label',\n",
    "                                                      cat_col='cat',\n",
    "                                                      m=0,\n",
    "                                                      statistic=False)\n",
    "    print(temp_stat)\n",
    "    apply_target_encode.transform_valid(temp_stat=temp_stat,\n",
    "                                        df=x_tr.loc[valid_idx, :],\n",
    "                                        cat_col='cat',\n",
    "                                        print_option=True)\n",
    "    assert 'cat_MEAN' in x_tr\n",
    "    print(fold)\n",
    "    print(x_tr.loc[train_idx,:])\n",
    "    print(x_tr.loc[valid_idx,:])\"\"\"\n",
    "x_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode (not ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_encode(df, subject_cols):\n",
    "    for str_col in subject_cols:\n",
    "        # ===== assumes Series of string =====\n",
    "        temp_dict = {value: i for i, value in enumerate(df[str_col].unique())}\n",
    "        df[str_col] = (df[str_col].map(temp_dict)).astype(np.int32)\n",
    "    del temp_dict, str_col; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_freq_encode(df, str_col, print_option=True):\n",
    "    temp_dict = {sample: df.loc[df[str_col]==sample].shape[0] for sample in df[str_col].unique()}\n",
    "    df[f'{str_col}_COUNT'] = df[str_col].map(temp_dict)\n",
    "    df[f'{str_col}_RATIO'] = df[str_col].map(temp_dict) / df[str_col].shape[0]\n",
    "    \n",
    "    if print_option:\n",
    "        print(f\"'{str_col}_COUNT',\")\n",
    "        print(f\"'{str_col}_RATIO',\")\n",
    "        print()\n",
    "    del temp_dict; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Related (Numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggs = {\n",
    "#     'uid': ['count'],\n",
    "#     'is_manual': ['sum', 'mean'],\n",
    "#     'elapsed_days_succeeded_created': ['mean', 'std', 'max', 'min'],\n",
    "#     'elapsed_days_created_premium': ['mean', 'std', 'max', 'min'],\n",
    "#     'elapsed_days_created': ['mean', 'std', 'max', 'min'],\n",
    "#     'elapsed_days_succeeded_premium': ['mean', 'std', 'max', 'min'],\n",
    "#     'elapsed_days_succeeded': ['mean', 'std', 'max', 'min'],\n",
    "#     'created_before_premium': ['sum', 'mean'],\n",
    "#     'created_after_premium': ['sum', 'mean'],\n",
    "#     'succeeded_before_premium': ['sum', 'mean'],\n",
    "#     'succeeded_before_premium': ['sum', 'mean'],\n",
    "# }\n",
    "# aggs.update({col: ['sum', 'mean'] for col in service_category_id_cols})\n",
    "\n",
    "# group_account_df = account_df.groupby(ID).agg(aggs)\n",
    "# group_account_df.columns = [f'{k}_{v.upper()}' for k, vs in aggs.items() for v in vs]\n",
    "# group_account_df = group_account_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cyclical(df, str_col):\n",
    "    # e.g. df['hr'] = df.timestamp.dt.hour; apply_cyclical(df, 'hr')\n",
    "    # ===== assumes integer array =====\n",
    "    # ===== assumes min and max exists in array =====\n",
    "    temp = pd.DataFrame()\n",
    "    temp['unique_sorted'] = (df[str_col] - df[str_col].min()).sort_values().unique()\n",
    "    int_max = temp.unique_sorted.max()\n",
    "    temp['sin'] = np.sin(2 * np.pi * temp.unique_sorted / int_max)\n",
    "    temp['cos'] = np.cos(2 * np.pi * temp.unique_sorted / int_max)\n",
    "    temp = temp.set_index('unique_sorted')\n",
    "    df[f'{str_col}_sin'] = (df[str_col] - df[str_col].min()).map(temp.sin)\n",
    "    df[f'{str_col}_cos'] = (df[str_col] - df[str_col].min()).map(temp.cos)\n",
    "    del temp, int_max; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mov_stat(df, str_col, list_windows, fix=False, print_option=True):\n",
    "\n",
    "    # ===== assumes timestamp is aligned =====\n",
    "    for win in list_windows:\n",
    "        rolled = df[str_col].rolling(window=win, min_periods=0)\n",
    "        mov_avg = rolled.mean().reset_index() #.astype(np.float16)\n",
    "        mov_max = rolled.max().reset_index() #.astype(np.float16)\n",
    "        mov_min = rolled.min().reset_index() #.astype(np.float16)\n",
    "        mov_std = rolled.std().reset_index() #.astype(np.float16)\n",
    "        if win >= 4:\n",
    "            mov_Q1 = rolled.quantile(0.25).reset_index() #.astype(np.float16)\n",
    "            mov_Q2 = rolled.quantile(0.5).reset_index() #.astype(np.float16)\n",
    "            mov_Q3 = rolled.quantile(0.75).reset_index() #.astype(np.float16)\n",
    "\n",
    "        if fix:\n",
    "            formula = int((win/2) - win)\n",
    "            df[f'{str_col}_movavg_{win}'] = mov_avg[f'{str_col}'].shift(formula)\n",
    "            df[f'{str_col}_movmax_{win}'] = mov_max[f'{str_col}'].shift(formula)\n",
    "            df[f'{str_col}_movmin_{win}'] = mov_min[f'{str_col}'].shift(formula)\n",
    "            df[f'{str_col}_movstd_{win}'] = mov_std[f'{str_col}'].shift(formula)\n",
    "            if win >= 4:\n",
    "                df[f'{str_col}_movQ1_{win}'] = mov_Q1[f'{str_col}'].shift(formula)\n",
    "                df[f'{str_col}_movQ2_{win}'] = mov_Q2[f'{str_col}'].shift(formula)\n",
    "                df[f'{str_col}_movQ3_{win}'] = mov_Q3[f'{str_col}'].shift(formula)\n",
    "            print()\n",
    "            del formula\n",
    "        else:\n",
    "            df[f'{str_col}_movavg_{win}'] = mov_avg[f'{str_col}']\n",
    "            df[f'{str_col}_movmax_{win}'] = mov_max[f'{str_col}']\n",
    "            df[f'{str_col}_movmin_{win}'] = mov_min[f'{str_col}']\n",
    "            df[f'{str_col}_movstd_{win}'] = mov_std[f'{str_col}']\n",
    "            if win >= 4:\n",
    "                df[f'{str_col}_movQ1_{win}'] = mov_Q1[f'{str_col}']\n",
    "                df[f'{str_col}_movQ2_{win}'] = mov_Q2[f'{str_col}']\n",
    "                df[f'{str_col}_movQ3_{win}'] = mov_Q3[f'{str_col}']\n",
    "            print()\n",
    "        \n",
    "        if print_option:\n",
    "            print('Generated features: apply_mov_stat')\n",
    "            print(f\"'{str_col}_movavg_{win}',\")\n",
    "            print(f\"'{str_col}_movmax_{win}',\")\n",
    "            print(f\"'{str_col}_movmin_{win}',\")\n",
    "            print(f\"'{str_col}_movstd_{win}',\")\n",
    "            if win >= 4:\n",
    "                print(f\"'{str_col}_movQ1_{win}',\")\n",
    "                print(f\"'{str_col}_movQ2_{win}',\")\n",
    "                print(f\"'{str_col}_movQ3_{win}',\")\n",
    "            print()\n",
    "            \n",
    "    del win, rolled, mov_avg, mov_max, mov_min, mov_std; gc.collect()\n",
    "    if any([val for val in list_windows if val >= 4]):\n",
    "        del mov_Q1, mov_Q2, mov_Q3; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear (log1p) Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nonlinear(df, subject_cols):\n",
    "    for col in subject_cols:\n",
    "        temp_count = df[f'{col}'].isna().sum()\n",
    "        df[f'{col}'] = np.log1p(df[f'{col}'])\n",
    "        if df[f'{col}'].isna().sum() > temp_count:\n",
    "            print(f\"New nan in '{col}' via apply_nonlinear\")\n",
    "    del col, temp_count; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_shift_feature(df, subject_cols, list_shift, print_option=True):\n",
    "    for col in subject_cols:\n",
    "        for step in list_shift:\n",
    "            df[f'{col}_shift_{step}'] = df[col].shift(int(step))\n",
    "            \n",
    "    if print_option:\n",
    "        print('Generated features: apply_shift_feature')\n",
    "        for col in subject_cols:\n",
    "            for step in list_shift:\n",
    "                print(f\"'{col}_shift_{step}',\")\n",
    "        print()\n",
    "        \n",
    "    del col, step; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oneth Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_oneth_feature(df, str_col, print_option=True):\n",
    "    import math\n",
    "    modify = np.vectorize(math.modf)\n",
    "    oneth, tenth = modify(df[str_col] / 10)\n",
    "    df[f'{str_col}_oneth'] = oneth * 10\n",
    "    \n",
    "    if print_option:\n",
    "        print('Generated features: apply_oneth_feature')\n",
    "        print(f\"'{str_col}_oneth',\")\n",
    "        print()\n",
    "        \n",
    "    del tenth; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nan Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_isna_feature(df, subject_cols, print_option=True):\n",
    "    binary_isna = [col+\"_isnan\" for col in subject_cols]\n",
    "    df[binary_isna] = df[subject_cols].isna().astype(int)\n",
    "    \n",
    "    if print_option:\n",
    "        print('Generated features: apply_oneth_feature')\n",
    "        for col in binary_isna:\n",
    "            print(f\"'{col}',\")\n",
    "        print()\n",
    "        \n",
    "    del binary_isna; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row nan Count Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_row_nan(df, print_option=True):\n",
    "    df['row_nan'] = df.isna().sum(axis=1).astype(np.int8)\n",
    "    \n",
    "    if print_option:\n",
    "        print('Generated features: apply_row_nan')\n",
    "        print(\"'row_nan',\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bruteforce Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bruteforce_combination(df, subject_cols, choose=2, print_option=True):\n",
    "    from itertools import combinations\n",
    "    comb = combinations(subject_cols, choose)\n",
    "    for feat_1, feat_2 in comb:\n",
    "        df[f'{feat_1}_.+_{feat_2}'] = df[f'{feat_1}'] + df[f'{feat_1}']\n",
    "        df[f'{feat_1}_.-_{feat_2}'] = df[f'{feat_1}'] - df[f'{feat_1}']\n",
    "        df[f'{feat_1}_.*_{feat_2}'] = df[f'{feat_1}'] * df[f'{feat_1}']\n",
    "        df[f'{feat_1}_./_{feat_2}'] = df[f'{feat_1}'] / df[f'{feat_1}']\n",
    "            \n",
    "    if print_option:\n",
    "        print('Generated features: bruteforce_feature_combination')\n",
    "        for feat_1, feat_2 in comb:\n",
    "            print(f\"'{feat_1}_.+_{feat_2}',\")\n",
    "            print(f\"'{feat_1}_.-_{feat_2}',\")\n",
    "            print(f\"'{feat_1}_.*_{feat_2}',\")\n",
    "            print(f\"'{feat_1}_./_{feat_2}',\")\n",
    "        print()\n",
    "            \n",
    "    del comb, feat_1, feat_2; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clip(df, str_col, pct_lower, pct_upper):\n",
    "    LB, UB = np.percentile(df[str_col], [pct_lower, pct_upper])\n",
    "    df[str_col] = np.clip(df[str_col], LB, UB)\n",
    "    del LB, UB; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_interpolation(df, subject_cols, int_order, supp_median_fill=False):\n",
    "    lin = lambda var: var.interpolate(method='linear', limit_direction='both')\n",
    "    pol = lambda var: var.interpolate(method='polynomial', order=int_order, limit_direction='both')\n",
    "    \n",
    "    # ===== in ASHRAE, grouping was done via site_id =====\n",
    "    # linear = df.groupby(grouping_col).apply(lin)\n",
    "    # polyno = df.groupby(grouping_col).apply(pol)\n",
    "    \n",
    "    linear = df[subject_cols].apply(lin)\n",
    "    polyno = df[subject_cols].apply(pol)\n",
    "    df[subject_cols] = (linear[subject_cols] + polyno[subject_cols]) * 0.5\n",
    "    \n",
    "    # ===== if missing value remains: =====\n",
    "    if supp_median_fill:\n",
    "        #[col for col in cols if temp[col].isna().sum() > 0]\n",
    "        for col in subject_cols:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "            del col\n",
    "    del lin, pol, linear, polyno; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Validation with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advarsarial_validation_lightgbm(\n",
    "    params,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    features,\n",
    "    categorical=[],\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "):\n",
    "    X_train_adv = X_train.copy()\n",
    "    X_test_adv = X_test.copy()\n",
    "    \n",
    "    X_train_adv['test'] = 0\n",
    "    X_test_adv['test'] = 1\n",
    "    \n",
    "    X_train_adv = pd.concat([X_train_adv, X_test_adv], axis=0).reset_index(drop=True)\n",
    "    y_train_adv = X_train_adv['test']\n",
    "    X_train_adv = X_train_adv.drop('test', axis=1)\n",
    "    \n",
    "    printl(f'{X_train_adv.shape}, {y_train_adv.shape}, {len(features)}')\n",
    "    \n",
    "    cv = build_cv_spliter(X_train_adv,\n",
    "                          y_train_adv,\n",
    "                          strategy='stratified',\n",
    "                          n_splits=n_splits,\n",
    "                          shuffle=shuffle,\n",
    "                          random_seed=seed)\n",
    "    \n",
    "    adv_metrics = {'AUC': roc_auc_score}\n",
    "    _, adv, feature_importance_df = run_kfold_lightgbm(params,\n",
    "                                                       X_train_adv,\n",
    "                                                       y_train_adv,\n",
    "                                                       X_train,\n",
    "                                                       cv,\n",
    "                                                       features,\n",
    "                                                       adv_metrics,\n",
    "                                                       categorical=cat_features)\n",
    "    \n",
    "    return adv, feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGroupKFold:\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        groups = pd.Series(groups)\n",
    "        unique_groups = np.unique(groups)\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        for tr_group_idx, va_group_idx in kf.split(unique_groups):\n",
    "            tr_groups, va_groups = unique_groups[tr_group_idx], unique_groups[va_group_idx]\n",
    "            tr_indices = groups[groups.isin(tr_groups)].index.to_list()\n",
    "            va_indices = groups[groups.isin(va_groups)].index.to_list()\n",
    "            yield tr_indices, va_indices\n",
    "            \n",
    "class StratifiedGroupKFold:\n",
    "    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    # Implementation based on this kaggle kernel:\n",
    "    #    https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        k = self.n_splits\n",
    "        rnd = check_random_state(self.random_state)\n",
    "            \n",
    "        # labels_num: zero-origin number of label\n",
    "        # ex) unique = [0,1,2,3] -> labels_num = 4\n",
    "        labels_num = np.max(y) + 1\n",
    "        \n",
    "        # y_counts_per_group: in-group label distribution\n",
    "        # y_distr: whole label distribution\n",
    "        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "        y_distr = Counter()\n",
    "        for label, g in zip(y, groups):\n",
    "            y_counts_per_group[g][label] += 1\n",
    "            y_distr[label] += 1\n",
    "\n",
    "        # y_counts_per_fold: in-fold label distribution\n",
    "        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "        groups_per_fold = defaultdict(set)\n",
    "        \n",
    "        # return mean std of per label counts when y_counts is in fold\n",
    "        def eval_y_counts_per_fold(y_counts, fold):\n",
    "            y_counts_per_fold[fold] += y_counts\n",
    "            std_per_label = []\n",
    "            for label in range(labels_num):\n",
    "                label_std = np.std(\n",
    "                    [y_counts_per_fold[i][label] / y_distr[label] for i in range(k)]\n",
    "                )\n",
    "                std_per_label.append(label_std)\n",
    "            y_counts_per_fold[fold] -= y_counts\n",
    "            return np.mean(std_per_label)\n",
    "        \n",
    "        # list of [group, y_counts]\n",
    "        # if shuffle: fold changes in same np.std(y_counts)\n",
    "        # ascending groups by degree of label variance\n",
    "        groups_and_y_counts = list(y_counts_per_group.items())\n",
    "        if self.shuffle:\n",
    "            rnd.shuffle(groups_and_y_counts)\n",
    "        groups_and_y_counts = sorted(groups_and_y_counts, key=lambda x: -np.std(x[1]))\n",
    "\n",
    "        # set fold for each group such that label distirbution will be uniform\n",
    "        for g, y_counts in groups_and_y_counts:\n",
    "            best_fold = None\n",
    "            min_eval = None\n",
    "            for i in range(k):\n",
    "                fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "                if min_eval is None or fold_eval < min_eval:\n",
    "                    min_eval = fold_eval\n",
    "                    best_fold = i\n",
    "            y_counts_per_fold[best_fold] += y_counts\n",
    "            groups_per_fold[best_fold].add(g)\n",
    "\n",
    "        all_groups = set(groups)\n",
    "        for i in range(k):\n",
    "            train_groups = all_groups - groups_per_fold[i]\n",
    "            test_groups = groups_per_fold[i]\n",
    "\n",
    "            train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "            test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "            yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cv_spliter(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    strategy='stratified',\n",
    "    n_splits=5,\n",
    "    group=None,\n",
    "    shuffle=True,\n",
    "    seed=8982,\n",
    "    return_indices=False,\n",
    "):\n",
    "    if strategy == 'kfold':\n",
    "        kf = KFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n",
    "        cv = kf.split(X_train)\n",
    "    elif strategy == 'stratified':\n",
    "        kf = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n",
    "        cv = kf.split(X_train, y_train)\n",
    "    elif strategy == 'group':\n",
    "        kf = MyGroupKFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n",
    "        cv = kf.split(X_train, y_train, group)\n",
    "    elif strategy == 'stratified-group':\n",
    "        kf = StratifiedGroupKFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n",
    "        cv = kf.split(X_train, y_train, group)\n",
    "    else:\n",
    "        raise NotImplementedError(f'strategy {strategy} not implemented.')\n",
    "\n",
    "    if not return_indices:\n",
    "        cv_spliter = []\n",
    "        for dev_idx, val_idx in cv:\n",
    "            cv_spliter.append([dev_idx, val_idx])\n",
    "        return cv_spliter\n",
    "    else:\n",
    "        fold_indices = np.zeros(len(X), dtype=np.int64)\n",
    "        for fold, (_, val_idx) in enumerate(cv):\n",
    "            fold_indices[val_idx] = int(fold)\n",
    "        return fold_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM (Binary Classification: max auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_kfold_clf(X_train, y_train, category_cols, split, bayes_opt=True,\n",
    "                  learning_rate=0.05, num_leaves=31, max_depth=-1,\n",
    "                  bagging_fraction=0.9, feature_fraction=0.9,\n",
    "                  min_child_weight=1e-3, min_data_in_leaf=20,\n",
    "                  lambda_l1=0.0, lambda_l2=0.0):\n",
    "    metric='auc'\n",
    "    params = {'objective': 'binary',\n",
    "              'metric': metric,\n",
    "              'boosting': 'gbdt',\n",
    "              'seed': 8982,\n",
    "              'learning_rate': learning_rate,\n",
    "              'num_leaves': int(num_leaves),\n",
    "              'max_depth': int(max_depth),\n",
    "              'bagging_freq': int(5),\n",
    "              'bagging_fraction': bagging_fraction,\n",
    "              'feature_fraction': feature_fraction,\n",
    "              'min_child_weight': min_child_weight,   \n",
    "              'min_data_in_leaf': int(min_data_in_leaf),\n",
    "              'lambda_l1': lambda_l1,\n",
    "              'lambda_l2': lambda_l2}\n",
    "              #'verbosity': int(-1)}\n",
    "             \n",
    "    #cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "    #print(cat_features)\n",
    "    \n",
    "    n_splits = len(split)\n",
    "    oofs = np.zeros(X_train.shape[0])\n",
    "    models = []; learning_curves = []; best_scores = []; valid_score = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    print(f'========== LightGBM Classifier training on : {X_train.shape} ==========')\n",
    "    for i, (train_idx, valid_idx) in enumerate(split):\n",
    "        d_train = lgb.Dataset(X_train.iloc[train_idx,:], label=y_train[train_idx], categorical_feature=category_cols)\n",
    "        d_valid = lgb.Dataset(X_train.iloc[valid_idx,:], label=y_train[valid_idx], categorical_feature=category_cols)\n",
    "        \n",
    "        print(f'========== LightGBM Classifier training: {i+1}/{n_splits} fold ==========')\n",
    "        learning_curve = {}\n",
    "        model = lgb.train(params,\n",
    "                          train_set=d_train,\n",
    "                          valid_sets=[d_train, d_valid],\n",
    "                          num_boost_round=5000,\n",
    "                          early_stopping_rounds=20,\n",
    "                          evals_result=learning_curve,\n",
    "                          verbose_eval=200#False,\n",
    "                          )\n",
    "        best_score = {f'train_{metric}': model.best_score['training'][f'{metric}'],\n",
    "                      f'valid_{metric}': model.best_score['valid_1'][f'{metric}']}\n",
    "        print()\n",
    "        oofs[valid_idx] = model.predict(X_train.iloc[valid_idx,:], num_iteration=model.best_iteration)\n",
    "        models.append(model)\n",
    "        learning_curves.append(learning_curve)\n",
    "        valid_score.append(best_score[f'valid_{metric}'])\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = common_cols + category_cols\n",
    "        fold_importance_df['importance'] = model.feature_importance()\n",
    "        fold_importance_df['fold'] = i+1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        del d_train, d_valid, fold_importance_df\n",
    "        gc.collect()\n",
    "        \n",
    "    valid_std_score = np.std(valid_score)\n",
    "    valid_avg_score = np.mean(valid_score)\n",
    "    print('====================')\n",
    "    print(f'CV AVG: {metric} - {valid_avg_score}')\n",
    "    print(f'CV STD: {metric} - {valid_std_score}')\n",
    "    print('====================')\n",
    "\n",
    "    if bayes_opt:\n",
    "        return valid_avg_score\n",
    "    else:\n",
    "        return oofs, models, feature_importance_df #best_scores, learning_curves\n",
    "\n",
    "def lgb_clf_bayes_opt(init_points=20, n_iteration=80):\n",
    "    bounds = {'learning_rate': (0.001, 0.3),\n",
    "              'num_leaves': (20, 500), \n",
    "              #'max_depth': (-1, 250),\n",
    "              'bagging_fraction' : (0.1, 1),\n",
    "              'feature_fraction' : (0.1, 1),\n",
    "              'min_child_weight': (0.001, 0.99),   \n",
    "              'min_data_in_leaf': (3, 700),\n",
    "              'lambda_l1': (0.1, 300), \n",
    "              'lambda_l2': (0.1, 300)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=lgb_kfold_clf, pbounds=bounds, random_state=8982)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iteration)\n",
    "    \n",
    "    print('Best score:', optimizer.max['target'])\n",
    "    print('Best set of parameters:')\n",
    "    print(optimizer.max['params'])\n",
    "    param = optimizer.max['params']; cv = optimizer.max['target']\n",
    "    return param, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM (Regression: min rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_kfold_reg(X_train, y_train, category_cols, split, bayes_opt=True,\n",
    "                  learning_rate=0.05, num_leaves=31, max_depth=-1,\n",
    "                  bagging_fraction=0.9, feature_fraction=0.9,\n",
    "                  min_child_weight=1e-3, min_data_in_leaf=20,\n",
    "                  lambda_l1=0.0, lambda_l2=0.0):\n",
    "    metric='rmse'\n",
    "    params = {'objective': 'regression',\n",
    "              'metric': metric,\n",
    "              'boosting': 'gbdt',\n",
    "              'seed': 8982,\n",
    "              'learning_rate': learning_rate,\n",
    "              'num_leaves': int(num_leaves),\n",
    "              'max_depth': int(max_depth),\n",
    "              'bagging_freq': int(5),\n",
    "              'bagging_fraction': bagging_fraction,\n",
    "              'feature_fraction': feature_fraction,\n",
    "              'min_child_weight': min_child_weight,   \n",
    "              'min_data_in_leaf': int(min_data_in_leaf),\n",
    "              'lambda_l1': lambda_l1,\n",
    "              'lambda_l2': lambda_l2}\n",
    "              #'verbosity': int(-1)}\n",
    "             \n",
    "    #cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "    #print(cat_features)\n",
    "    \n",
    "    n_splits = len(split)\n",
    "    oofs = np.zeros(X_train.shape[0])\n",
    "    models = []; learning_curves = []; valid_scores = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    print(f'========== LightGBM Regressor training on: {X_train.shape} ==========')\n",
    "    for i, (train_idx, valid_idx) in enumerate(split):\n",
    "        d_train = lgb.Dataset(X_train.iloc[train_idx,:], label=y_train[train_idx], categorical_feature=category_cols)\n",
    "        d_valid = lgb.Dataset(X_train.iloc[valid_idx,:], label=y_train[valid_idx], categorical_feature=category_cols)\n",
    "        \n",
    "        print(f'========== LightGBM Regressor training: {i+1}/{n_splits} fold ==========')\n",
    "        learning_curve = {}\n",
    "        model = lgb.train(params,\n",
    "                          train_set=d_train,\n",
    "                          valid_sets=[d_train, d_valid],\n",
    "                          num_boost_round=5000,\n",
    "                          early_stopping_rounds=20,\n",
    "                          evals_result=learning_curve,\n",
    "                          verbose_eval=200#False,\n",
    "                          )\n",
    "        print()\n",
    "        oofs[valid_idx] = model.predict(X_train.iloc[valid_idx,:], num_iteration=model.best_iteration)\n",
    "        models.append(model)\n",
    "        learning_curves.append(learning_curve)\n",
    "        valid_scores.append(model.best_score['valid_1'][f'{metric}'])\n",
    "          \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = common_cols + category_cols\n",
    "        fold_importance_df['importance'] = model.feature_importance()\n",
    "        fold_importance_df['fold'] = i+1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)  \n",
    "        \n",
    "        del d_train, d_valid, fold_importance_df\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    valid_std_score = np.std(valid_scores)\n",
    "    valid_avg_score = np.mean(valid_scores)\n",
    "    print('====================')\n",
    "    print(f'CV AVG: {metric} - {valid_avg_score}')\n",
    "    print(f'CV STD: {metric} - {valid_std_score}')\n",
    "    print('====================')\n",
    "    \n",
    "    if bayes_opt:\n",
    "        return -valid_avg_score\n",
    "    else:\n",
    "        return oofs, models, feature_importance_df #best_scores, learning_curves\n",
    "\n",
    "def lgb_reg_bayes_opt(init_points=20, n_iteration=80):\n",
    "    bounds = {'learning_rate': (0.001, 0.3),\n",
    "              'num_leaves': (20, 500),\n",
    "              #'max_depth': (-1, 250),\n",
    "              'bagging_fraction' : (0.1, 1),\n",
    "              'feature_fraction' : (0.1, 1),\n",
    "              'min_child_weight': (0.001, 0.99),   \n",
    "              'min_data_in_leaf': (3, 700),\n",
    "              'lambda_l1': (0.1, 300), \n",
    "              'lambda_l2': (0.1, 300)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=lgb_kfold_reg, pbounds=bounds, random_state=8982)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iteration)\n",
    "    \n",
    "    print('Best score:', -optimizer.max['target'])\n",
    "    print('Best set of parameters:')\n",
    "    print(optimizer.max['params'])\n",
    "    param = optimizer.max['params']; cv = -optimizer.max['target']\n",
    "    return param, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_pred(X_test, models):\n",
    "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'========== LightGBM Predicting with {i+1}-th model ==========')\n",
    "        y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        y_test_pred_total += y_pred_test\n",
    "    y_test_pred_total /= len(models)\n",
    "    return y_test_pred_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost (Binary Classification: max AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_kfold_clf(X_train, y_train, category_cols, split, bayes_opt=True,\n",
    "                learning_rate=0.03, num_leaves=31, max_depth=6,\n",
    "                subsample=0.8, bagging_temperature=1.0, colsample_bylevel=1.0,\n",
    "                min_data_in_leaf=1, l2_leaf_reg=3.0, random_strength=1.0):\n",
    "    loss = 'Logloss'\n",
    "    metric = 'AUC'\n",
    "    params = {'loss_function': loss,\n",
    "              'eval_metric': metric,\n",
    "              'boosting_type': 'Plain',\n",
    "              'random_seed': 8982,\n",
    "              'num_boost_round': 5000,\n",
    "              'early_stopping_rounds': 20,\n",
    "              'use_best_model': True,\n",
    "              # 'grow_policy': 'SymmetricTree','Depthwise','Lossguide',\n",
    "              'nan_mode': 'Max',\n",
    "              'od_type': 'Iter',\n",
    "              'verbose': 200,\n",
    "              \n",
    "              'learning_rate': learning_rate,\n",
    "              'num_leaves': int(num_leaves),\n",
    "              'max_depth': int(max_depth),\n",
    "              'subsample': subsample, #bf?\n",
    "              'bagging_temperature': bagging_temperature, #bf?\n",
    "              'colsample_bylevel': colsample_bylevel, #ff\n",
    "              'min_data_in_leaf': int(min_data_in_leaf),\n",
    "              'l2_leaf_reg': l2_leaf_reg,\n",
    "              'random_strength': random_strength}\n",
    "    \n",
    "    n_splits = len(split)\n",
    "    oofs = np.zeros(X_train.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    models = []; learning_curves = []; valid_losses = []; valid_metrics = []\n",
    "    print(f'========== CatBoost Classifier training on: {X_train.shape} ==========')\n",
    "    for i, (train_idx, valid_idx) in enumerate(split):\n",
    "        print(f'========== CatBoost Classifier training: {i+1}/{n_splits} ==========')\n",
    "        train_d = cb.Pool(data=X_train.loc[train_idx],\n",
    "                          label=y_train[train_idx],\n",
    "                          cat_features=category_cols)\n",
    "        valid_d = cb.Pool(data=X_train.loc[valid_idx],\n",
    "                          label=y_train[valid_idx],\n",
    "                          cat_features=category_cols)\n",
    "        \n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        model.fit(train_d, eval_set=valid_d)\n",
    "        \n",
    "        oofs[valid_idx] = model.predict_proba(X_train.loc[valid_idx])[:,1]\n",
    "        models.append(model)\n",
    "        valid_losses.append(model.best_score_['validation'][f'{loss}'])\n",
    "        valid_metrics.append(model.best_score_['validation'][f'{metric}'])\n",
    "          \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = common_cols + category_cols\n",
    "        fold_importance_df['importance'] = model.get_feature_importance()\n",
    "        fold_importance_df['fold'] = i+1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "          \n",
    "        del train_d, valid_d, model, fold_importance_df\n",
    "        gc.collect()\n",
    "        \n",
    "    print('====================')\n",
    "    print(f'CV AVG:\\n{loss} - {np.mean(valid_losses)}\\n{metric} - {np.mean(valid_metrics)}')\n",
    "    print(f'CV STD:\\n{loss} - {np.std(valid_losses)}\\n{metric} - {np.std(valid_metrics)}')\n",
    "    print('====================')\n",
    "    \n",
    "    if bayes_opt:\n",
    "        return np.mean(valid_metrics)\n",
    "    else:\n",
    "        return oofs, models, feature_importance_df\n",
    "\n",
    "def cb_clf_bayes_opt(init_points=20, n_iteration=80):\n",
    "    bounds = {'learning_rate': (0.001, 0.3),\n",
    "              'num_leaves': (16, 288), \n",
    "              'max_depth': (3, 16),\n",
    "              'subsample' : (0.1, 1),\n",
    "              'bagging_temperature' : (0, 100),\n",
    "              'colsample_bylevel': (0.001, 1),   \n",
    "              'min_data_in_leaf': (3, 700),\n",
    "              'l2_leaf_reg': (0.1, 300), \n",
    "              'random_strength': (0, 100)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=cb_kfold_clf, pbounds=bounds, random_state=8982)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iteration)\n",
    "    \n",
    "    print('Best score:', optimizer.max['target'])\n",
    "    print('Best set of parameters:')\n",
    "    print(optimizer.max['params'])\n",
    "    param = optimizer.max['params']; cv = optimizer.max['target']\n",
    "    return param, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_pred_clf(X_test, models):\n",
    "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'========== CatBoost Predicting with {i+1}-th model ==========')\n",
    "        y_pred_test = model.predict_proba(X_test)[:,1]\n",
    "        y_test_pred_total += y_pred_test\n",
    "    y_test_pred_total /= len(models)\n",
    "    return y_test_pred_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost (Regression: min RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_kfold_reg(X_train, y_train, category_cols, split, bayes_opt=True,\n",
    "                learning_rate=0.03, num_leaves=31, max_depth=6,\n",
    "                subsample=0.8, bagging_temperature=1.0, colsample_bylevel=1.0,\n",
    "                min_data_in_leaf=1, l2_leaf_reg=3.0, random_strength=1.0):\n",
    "    loss = 'RMSE'\n",
    "    metric = 'RMSE'\n",
    "    params = {'loss_function': loss,\n",
    "              'eval_metric': metric,\n",
    "              'boosting_type': 'Plain',\n",
    "              'random_seed': 8982,\n",
    "              'num_boost_round': 5000,\n",
    "              'early_stopping_rounds': 20,\n",
    "              'use_best_model': True,\n",
    "              # 'grow_policy': 'SymmetricTree','Depthwise','Lossguide',\n",
    "              'nan_mode': 'Max',\n",
    "              'od_type': 'Iter',\n",
    "              'verbose': 200,\n",
    "              \n",
    "              'learning_rate': learning_rate,\n",
    "              'num_leaves': int(num_leaves),\n",
    "              'max_depth': int(max_depth),\n",
    "              'subsample': subsample, #bf?\n",
    "              'bagging_temperature': bagging_temperature, #bf?\n",
    "              'colsample_bylevel': colsample_bylevel, #ff\n",
    "              'min_data_in_leaf': int(min_data_in_leaf),\n",
    "              'l2_leaf_reg': l2_leaf_reg,\n",
    "              'random_strength': random_strength}\n",
    "    \n",
    "    n_splits = len(split)\n",
    "    oofs = np.zeros(X_train.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    models = []; valid_losses = []; valid_metrics = []\n",
    "    print(f'========== CatBoost Regressor training on: {X_train.shape} ==========')\n",
    "    for i, (train_idx, valid_idx) in enumerate(split):\n",
    "        print(f'========== CatBoost Regressor training: {i+1}/{n_splits} ==========')\n",
    "        train_d = cb.Pool(data=X_train.loc[train_idx],\n",
    "                          label=y_train[train_idx],\n",
    "                          cat_features=category_cols)\n",
    "        valid_d = cb.Pool(data=X_train.loc[valid_idx],\n",
    "                          label=y_train[valid_idx],\n",
    "                          cat_features=category_cols)\n",
    "        \n",
    "        model = cb.CatBoostRegressor(**params)\n",
    "        model.fit(train_d, eval_set=valid_d)\n",
    "        \n",
    "        oofs[valid_idx] = model.predict(X_train.loc[valid_idx])\n",
    "        models.append(model)\n",
    "        # valid_losses.append(model.best_score_['validation'][f'{loss}'])\n",
    "        valid_metrics.append(model.best_score_['validation'][f'{metric}'])\n",
    "          \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = common_cols + category_cols\n",
    "        fold_importance_df['importance'] = model.get_feature_importance()\n",
    "        fold_importance_df['fold'] = i+1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "          \n",
    "        del train_d, valid_d, model, fold_importance_df\n",
    "        gc.collect()\n",
    "    \n",
    "    assert loss == metric\n",
    "    print('====================')\n",
    "    print(f'CV AVG: {metric} - {np.mean(valid_metrics)}')\n",
    "    print(f'CV STD: {metric} - {np.std(valid_metrics)}')\n",
    "    print('====================')\n",
    "    \n",
    "    if bayes_opt:\n",
    "        return -np.mean(valid_metrics)\n",
    "    else:\n",
    "        return oofs, models, feature_importance_df\n",
    "\n",
    "def cb_reg_bayes_opt(init_points=20, n_iteration=80):\n",
    "    bounds = {'learning_rate': (0.001, 0.3),\n",
    "              'num_leaves': (16, 288), \n",
    "              'max_depth': (3, 16),\n",
    "              'subsample' : (0.1, 1),\n",
    "              'bagging_temperature' : (0, 100),\n",
    "              'colsample_bylevel': (0.001, 1),   \n",
    "              'min_data_in_leaf': (3, 700),\n",
    "              'l2_leaf_reg': (0.1, 300), \n",
    "              'random_strength': (0, 100)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=cb_kfold_clf, pbounds=bounds, random_state=8982)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iteration)\n",
    "    \n",
    "    print('Best score:', -optimizer.max['target'])\n",
    "    print('Best set of parameters:')\n",
    "    print(optimizer.max['params'])\n",
    "    param = optimizer.max['params']; cv = -optimizer.max['target']\n",
    "    return param, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_pred_reg(X_test, models):\n",
    "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'========== CatBoost Predicting with {i+1}-th model ==========')\n",
    "        y_pred_test = model.predict(X_test)#[:,1]\n",
    "        y_test_pred_total += y_pred_test\n",
    "    y_test_pred_total /= len(models)\n",
    "    return y_test_pred_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there no need to set cb.predict(, best_iteration=?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (Binary Classification: max auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# encode categorical cols beforehand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_kfold_clf(X_train, y_train, split, bayes_opt=True,\n",
    "                  eta=0.3, gamma=0, max_depth=6, min_child_weight=1,\n",
    "                  subsample=1, colsample_bytree=1.0, colsample_bylevel=1.0,\n",
    "                  colsample_bynode=1.0, reg_lambda=1.0, reg_alpha=0.0):\n",
    "    metric = 'auc'\n",
    "    params = {'objective': 'binary:logistic',\n",
    "              'eval_metric': metric,\n",
    "              'booster': 'gbtree', # 'dart',\n",
    "              'seed': 8982,\n",
    "\n",
    "              'missing': np.nan,\n",
    "              # when dart: 'rate_drop': (0.0, 1.0),\n",
    "              # 'grow_policy': 'depthwise','lossguide',\n",
    "              # 'verbosity': 1, #0\n",
    "              # 'base_score': 0.5 <- initial leaf prediction\n",
    "              \n",
    "              'eta': eta,\n",
    "              # 'gamma': gamma, # pruning phase of split in XGBoost unique tree\n",
    "              'max_depth': int(max_depth),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample, # 0.5 - randomly sample half of the training data prior to growing trees\n",
    "              'colsample_bytree': colsample_bytree, # subsample ratio of columns when constructing each tree\n",
    "              'colsample_bylevel': colsample_bylevel, # subsample ratio of columns for each level\n",
    "              'colsample_bynode': colsample_bynode, # subsample ratio of columns for each node (split)\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'reg_alpha': reg_alpha}\n",
    "    \n",
    "    n_splits = len(split)\n",
    "    oofs = np.zeros(X_train.shape[0])\n",
    "    \n",
    "    models = []; learning_curves = []; valid_losses = []; valid_metrics = []\n",
    "    print(f'========== XGBoost Classifier training on: {X_train.shape} ==========')\n",
    "    for i, (train_idx, valid_idx) in enumerate(split):\n",
    "        print(f'========== XGBoost Classifier training: {i+1}/{n_splits} ==========')\n",
    "        train_d = xgb.DMatrix(data=X_train.loc[train_idx],\n",
    "                              label=y_train[train_idx],\n",
    "                              feature_names=common_cols+category_cols)\n",
    "                              #cat_features=category_cols)\n",
    "        valid_d = xgb.DMatrix(data=X_train.loc[valid_idx],\n",
    "                              label=y_train[valid_idx],\n",
    "                              feature_names=common_cols+category_cols)\n",
    "                              #cat_features=category_cols)\n",
    "        learning_curve = {}\n",
    "        model = xgb.train(params,\n",
    "                          train_d,\n",
    "                          evals=[(train_d, 'train'), (valid_d, 'valid')],\n",
    "                          num_boost_round=5000,\n",
    "                          early_stopping_rounds=20,\n",
    "                          verbose_eval=200,#False\n",
    "                          evals_result=learning_curve)\n",
    "        oofs[valid_idx] = model.predict(valid_d, ntree_limit=model.best_ntree_limit)\n",
    "        models.append(model)\n",
    "        learning_curves.append(learning_curve)\n",
    "        valid_metrics.append(model.best_score)\n",
    "          \n",
    "        del train_d, valid_d, model\n",
    "        gc.collect()\n",
    "        \n",
    "    print('====================')\n",
    "    print(f'CV AVG: {metric} - {np.mean(valid_metrics)}')\n",
    "    print(f'CV STD: {metric} - {np.std(valid_metrics)}')\n",
    "    print('====================')\n",
    "    \n",
    "    if bayes_opt:\n",
    "        return np.mean(valid_metrics)\n",
    "    else:\n",
    "        return oofs, models #, learning_curves\n",
    "\n",
    "def cb_clf_bayes_opt(init_points=20, n_iteration=80):\n",
    "    bounds = {'eta': (0.001, 0.3),\n",
    "              'max_depth': (3, 250),\n",
    "              'min_child_weight': (0, 100),\n",
    "              'subsample': (0.1, 1),\n",
    "              'colsample_bytree': (0.1, 1),\n",
    "              'colsample_bylevel': (0.1, 1),\n",
    "              'colsample_bynode': (0.1, 1),\n",
    "              'reg_lambda': (0, 300),\n",
    "              'reg_alpha': (0, 300)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=cb_kfold_clf, pbounds=bounds, random_state=8982)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iteration)\n",
    "    \n",
    "    print('Best score:', optimizer.max['target'])\n",
    "    print('Best set of parameters:')\n",
    "    print(optimizer.max['params'])\n",
    "    param = optimizer.max['params']; cv = optimizer.max['target']\n",
    "    return param, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (Regression: max rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_kfold_reg(X_train, y_train, split, bayes_opt=True,\n",
    "                  eta=0.3, gamma=0, max_depth=6, min_child_weight=1,\n",
    "                  subsample=1, colsample_bytree=1.0, colsample_bylevel=1.0,\n",
    "                  colsample_bynode=1.0, reg_lambda=1.0, reg_alpha=0.0):\n",
    "    metric = 'rmse'\n",
    "    params = {'objective': 'reg:squarederror',\n",
    "              'eval_metric': metric,\n",
    "              'booster': 'gbtree', # 'dart',\n",
    "              'seed': 8982,\n",
    "\n",
    "              'missing': np.nan,\n",
    "              # when dart: 'rate_drop': (0.0, 1.0),\n",
    "              # 'grow_policy': 'depthwise','lossguide',\n",
    "              # 'verbosity': 1, #0\n",
    "              # 'base_score': 0.5 <- initial leaf prediction\n",
    "              \n",
    "              'eta': eta,\n",
    "              # 'gamma': gamma, # pruning phase of split in XGBoost unique tree\n",
    "              'max_depth': int(max_depth),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample, # 0.5 - randomly sample half of the training data prior to growing trees\n",
    "              'colsample_bytree': colsample_bytree, # subsample ratio of columns when constructing each tree\n",
    "              'colsample_bylevel': colsample_bylevel, # subsample ratio of columns for each level\n",
    "              'colsample_bynode': colsample_bynode, # subsample ratio of columns for each node (split)\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'reg_alpha': reg_alpha}\n",
    "    \n",
    "    n_splits = len(split)\n",
    "    oofs = np.zeros(X_train.shape[0])\n",
    "    \n",
    "    models = []; learning_curves = []; valid_losses = []; valid_metrics = []\n",
    "    print(f'========== XGBoost Regressor training on: {X_train.shape} ==========')\n",
    "    for i, (train_idx, valid_idx) in enumerate(split):\n",
    "        print(f'========== XGBoost Regressor training: {i+1}/{n_splits} ==========')\n",
    "        train_d = xgb.DMatrix(data=X_train.loc[train_idx],\n",
    "                              label=y_train[train_idx],\n",
    "                              feature_names=common_cols+category_cols)\n",
    "                              #cat_features=category_cols)\n",
    "        valid_d = xgb.DMatrix(data=X_train.loc[valid_idx],\n",
    "                              label=y_train[valid_idx],\n",
    "                              feature_names=common_cols+category_cols)\n",
    "                              #cat_features=category_cols)\n",
    "        learning_curve = {}\n",
    "        model = xgb.train(params,\n",
    "                          train_d,\n",
    "                          evals=[(train_d, 'train'), (valid_d, 'valid')],\n",
    "                          num_boost_round=5000,\n",
    "                          early_stopping_rounds=20,\n",
    "                          verbose_eval=200,#False\n",
    "                          evals_result=learning_curve)\n",
    "        oofs[valid_idx] = model.predict(valid_d, ntree_limit=model.best_ntree_limit)\n",
    "        models.append(model)\n",
    "        learning_curves.append(learning_curve)\n",
    "        valid_metrics.append(model.best_score)\n",
    "          \n",
    "        del train_d, valid_d, model\n",
    "        gc.collect()\n",
    "        \n",
    "    print('====================')\n",
    "    print(f'CV AVG: {metric} - {np.mean(valid_metrics)}')\n",
    "    print(f'CV STD: {metric} - {np.std(valid_metrics)}')\n",
    "    print('====================')\n",
    "    \n",
    "    if bayes_opt:\n",
    "        return -np.mean(valid_metrics)\n",
    "    else:\n",
    "        return oofs, models #, learning_curves\n",
    "\n",
    "def xgb_clf_bayes_opt(init_points=20, n_iteration=80):\n",
    "    bounds = {'eta': (0.001, 0.3),\n",
    "              'max_depth': (3, 250),\n",
    "              'min_child_weight': (0, 100),\n",
    "              'subsample': (0.1, 1),\n",
    "              'colsample_bytree': (0.1, 1),\n",
    "              'colsample_bylevel': (0.1, 1),\n",
    "              'colsample_bynode': (0.1, 1),\n",
    "              'reg_lambda': (0, 300),\n",
    "              'reg_alpha': (0, 300)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=cb_kfold_clf, pbounds=bounds, random_state=8982)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iteration)\n",
    "    \n",
    "    print('Best score:', -optimizer.max['target'])\n",
    "    print('Best set of parameters:')\n",
    "    print(optimizer.max['params'])\n",
    "    param = optimizer.max['params']; cv = -optimizer.max['target']\n",
    "    return param, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_pred(X_test, models):\n",
    "    y_pred_test_total = np.zeros(X_test.shape[0])\n",
    "    test_d = xgb.DMatrix(X_test)\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'========== XGBoost Predicting with {i+1}-th model ==========')\n",
    "        y_pred_test = model.predict(test_d, ntree_limit=model.best_ntree_limit)\n",
    "        y_pred_test_total += y_pred_test\n",
    "    y_pred_test_total /= len(models)\n",
    "    return y_pred_test_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neuralnet(\n",
    "    recipe,\n",
    "    loss='mse',\n",
    "    optimizer='adam',\n",
    "    lr=1e-3,\n",
    "    monitor='val_loss',\n",
    "    es_patience=-1,\n",
    "    restore_best_weights=True,\n",
    "    lr_scheduler='none',\n",
    "    lr_factor=0.1,\n",
    "    lr_patience=5,\n",
    "    seed=42,\n",
    "    **_,\n",
    "):\n",
    "    tf.random.set_seed(seed)\n",
    "    model = keras.models.model_from_json(recipe)\n",
    "    \n",
    "    if loss == 'mse':\n",
    "        loss = keras.losses.mean_squared_error\n",
    "    elif loss == 'bce':\n",
    "        loss = keras.losses.binary_crossentropy\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(lr)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    callbacks = []\n",
    "    \n",
    "    if es_patience >= 0:\n",
    "        es = keras.callbacks.EarlyStopping(monitor=monitor,\n",
    "                                           patience=es_patience,\n",
    "                                           restore_best_weights=restore_best_weights,\n",
    "                                           verbose=1)\n",
    "        callbacks.append(es)\n",
    "    \n",
    "    if lr_scheduler == 'none':\n",
    "        pass\n",
    "    elif lr_scheduler == 'reduce_on_plateau':\n",
    "        lr_sche = keras.callbacks.ReduceLROnPlateau(monitor=monitor,\n",
    "                                                    factor=lr_factor,\n",
    "                                                    patience=lr_patience,\n",
    "                                                    verbose=1)\n",
    "        callbacks.append(lr_sche)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    return model, callbacks\n",
    "\n",
    "\n",
    "def train_neuralnet(\n",
    "    params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=None,\n",
    "):\n",
    "    model, callbacks = build_neuralnet(**params)\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              validation_data=validation_data,\n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=params['epochs'],\n",
    "              callbacks=callbacks)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_kfold_neuralnet(\n",
    "    params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    cv,\n",
    "    features,\n",
    "    metrics,\n",
    "):\n",
    "    oof = np.zeros(len(X_train))\n",
    "    predictions = np.zeros(len(X_test))\n",
    "    \n",
    "    n_splits = len(cv)\n",
    "    printl(f\"k={n_splits} folds neuralnet running...\")\n",
    "    printl(f\"train data/feature shape: {X_train[features].shape}\")\n",
    "    \n",
    "    for fold, (dev_idx, val_idx) in enumerate(cv):\n",
    "        validation_data = [X_train.loc[val_idx, features], y_train[val_idx]]\n",
    "        model = train_neuralnet(params,\n",
    "                                X_train.loc[dev_idx, features],\n",
    "                                y_train[dev_idx],\n",
    "                                validation_data=validation_data)\n",
    "        \n",
    "        oof[val_idx] = model.predict(X_train.loc[val_idx, features].values)[:,0]\n",
    "        predictions += model.predict(X_test[features].values)[:,0] / n_splits\n",
    "        \n",
    "        msg = f'fold: {fold}'\n",
    "        for name, func in metrics.items():\n",
    "            score = func(y_train[val_idx], oof[val_idx])\n",
    "            msg += f' - {name}: {score:.5f}'\n",
    "        printl(msg)\n",
    "    \n",
    "    msg = f'CV score'\n",
    "    for name, func in metrics.items():\n",
    "        score = func(y_train, oof)\n",
    "        msg += f' - {name}: {score:.5f}'\n",
    "    printl(msg)\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(\n",
    "    feature_importance_df,\n",
    "    feature_name='feature',\n",
    "    importance_name=['split', 'gain'],\n",
    "    top_k=50,\n",
    "    fig_width=16,\n",
    "    fig_height=8,\n",
    "    fontsize=14,\n",
    "):\n",
    "    if isinstance(importance_name, str):\n",
    "        importance_name = [importance_name]\n",
    "    \n",
    "    num_importance = len(importance_name)\n",
    "    plt.figure(figsize=(fig_width, fig_height*num_importance))\n",
    "    gs = gridspec.GridSpec(1, num_importance)\n",
    "    \n",
    "    def _fetch_best_features(df, fimp='gain'):\n",
    "        cols = (df[[feature_name, fimp]]\n",
    "                .groupby(feature_name)\n",
    "                .mean()\n",
    "                .sort_values(by=fimp, ascending=False)\n",
    "                .index\n",
    "                .values[:top_k])\n",
    "        return cols, df.loc[df[feature_name].isin(cols)]\n",
    "    \n",
    "    for i, fimp in enumerate(importance_name):\n",
    "        cols, best_features = _fetch_best_features(feature_importance_df, fimp)\n",
    "        ax = plt.subplot(gs[0, i])\n",
    "        sns.barplot(x=fimp, y=feature_name, data=best_features, order=cols, ax=ax)\n",
    "        title = f'Features {fimp} importance (averaged/folds)'\n",
    "        plt.title(title, fontweight='bold', fontsize=fontsize)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "# or this\n",
    "# fold_importance_df.plot.barh(x='feature', y='gain', figsize=(13,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Feature Elimination by LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterative_CV:\n",
    "    def __init__(self, X_train_full, y_train, eval_cols, metric):\n",
    "        self.X_train_full = X_train_full\n",
    "        self.y_train = y_train\n",
    "        self.eval_cols = eval_cols\n",
    "        self.metric = metric\n",
    "    \n",
    "    # =====\n",
    "    # eliminates/imputes one feature at a time,\n",
    "    # returns list with options and discards\n",
    "    # ====\n",
    "    \n",
    "    def iter_cv_elim():\n",
    "        excl_improve = []; excl_worse = []\n",
    "        if self.metric == 'rmse':\n",
    "            init_valid_avg_score = -1 * lgb_kfold(self.X_train_full, self.y_train, bayes_opt=True)\n",
    "            print(f'[Iter_Feature_Elim] Current best score is {init_valid_avg_score}')\n",
    "            for cols in tqdm(self.eval_cols):\n",
    "                temp_cols = list(set(self.X_train_full.columns) - {col})\n",
    "                X_train = self.X_train_full[temp_cols]\n",
    "                new_valid_avg_score = -1 * lgb_kfold(X_train, self.y_train, bayes_opt=True)\n",
    "                degree = new_valid_avg_score - init_valid_avg_score\n",
    "                if degree < 0:\n",
    "                    pct = 100 * (-1 * degree / init_valid_avg_score)\n",
    "                    excl_improve.append([col, pct])\n",
    "                    print(f\"[Iter_Feature_Elim] '{col}', exclusion improved (lowered) avg CV by {pct}pct.\")\n",
    "                else:\n",
    "                    pct = 100 * (degree / init_valid_avg_score)\n",
    "                    excl_worse.append([col, pct])\n",
    "                    print(f\"[Iter_Feature_Elim] '{col}', exclusion worsened (raised) avg CV by {pct}pct.\")\n",
    "        elif self.metric == 'auc':\n",
    "            init_valid_avg_score = lgb_skfold(self.X_train_full, self.y_train, bayes_opt=True)\n",
    "            print(f'[Iter_Feature_Elim] Current best score is {init_valid_avg_score}')\n",
    "            for col in tqdm(self.eval_cols):\n",
    "                temp_cols = list(set(self.X_train_full.columns) - {col})\n",
    "                X_train = self.X_train_full[temp_cols]\n",
    "                new_valid_avg_score = lgb_skfold(X_train, self.y_train, bayes_opt=True)\n",
    "                degree = new_valid_avg_score - init_valid_avg_score\n",
    "                if degree > 0:\n",
    "                    pct = 100 * (degree / init_valid_avg_score)\n",
    "                    excl_improve.append([col, pct])\n",
    "                    print(f\"[Iter_Feature_Elim] '{col}', exclusion improved (raised) avg CV by {pct}pct.\")\n",
    "                else:\n",
    "                    pct = 100 * (-1 * degree / init_valid_avg_score)\n",
    "                    excl_worse.append([col, pct])\n",
    "                    print(f\"[Iter_Feature_Elim] '{col}', exclusion worsened (lowered) avg CV by {pct}pct.\")\n",
    "\n",
    "        excl_improve.sort(key=lambda lst: lst[1])\n",
    "        excl_worse.sort(key=lambda lst: lst[1])\n",
    "        del init_valid_avg_score, cols, temp_cols, X_train, new_valid_avg_score, degree, pct\n",
    "        gc.collect()\n",
    "        return excl_improve, excl_worse\n",
    "    \n",
    "    def iter_cv_rank():\n",
    "        impt = []\n",
    "        if self.metric == 'rmse':\n",
    "            for col in tqdm(self.eval_cols):\n",
    "                X_train = self.X_train_full[col]\n",
    "                assert X_train.shape[1] == 1\n",
    "                print(f\"[Iter_Feature_Rank] '{col}', evaluation ongoing.\")\n",
    "                valid_avg_score = -1 * lgb_kfold(X_train, self.y_train, bayes_opt=True)\n",
    "                impt.append([col, valid_avg_score])\n",
    "        elif self.metric == 'auc':\n",
    "            for col in tqdm(self.eval_cols):\n",
    "                X_train = self.X_train_full[col]\n",
    "                assert X_train.shape[1] == 1\n",
    "                print(f\"[Iter_Feature_Rank] '{col}', evaluation ongoing.\")\n",
    "                valid_avg_score = lgb_skfold(X_train, self.y_train, bayes_opt=True)\n",
    "                impt.append([col, valid_avg_score])\n",
    "        impt.sort(key=lambda lst: lst[1])\n",
    "        del col, X_train, valid_avg_score\n",
    "        gc.collect()\n",
    "        return impt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Importance Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_lgb_fimp(\n",
    "    params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    features,\n",
    "    shuffle,\n",
    "    seed=42,\n",
    "    categorical=[]\n",
    "):\n",
    "    # Shuffle target if required\n",
    "    y = y_train.copy()\n",
    "    if shuffle:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        y = y_train.copy().sample(frac=1.0)\n",
    "    \n",
    "    arg_categorical = categorical if len(categorical) > 0 else 'auto'\n",
    "    dtrain = lgb.Dataset(X_train[features],\n",
    "                         label=y.values,\n",
    "                         categorical_feature=arg_categorical)\n",
    "    \n",
    "    # Fit the model\n",
    "    clf = lgb.train(params, dtrain)\n",
    "\n",
    "    # Get feature importances\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = features\n",
    "    imp_df['split'] = clf.feature_importance(importance_type='split')\n",
    "    imp_df['gain'] = clf.feature_importance(importance_type='gain')\n",
    "    \n",
    "    return imp_df\n",
    "\n",
    "\n",
    "def null_importance_selection(\n",
    "    params,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    features,\n",
    "    seed=42,\n",
    "    categorical=[],\n",
    "    num_actual_run=1,\n",
    "    num_null_run=40,\n",
    "    eps=1e-10,\n",
    "    valid_percentile=75,\n",
    "):\n",
    "    actual_imp_df = pd.DataFrame()\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    for i in tqdm(range(num_actual_run)):\n",
    "        seed = np.random.randint(1000)\n",
    "        imp_df = _get_lgb_fimp(params,\n",
    "                               X_train,\n",
    "                               y_train,\n",
    "                               features,\n",
    "                               shuffle=False,\n",
    "                               seed=seed,\n",
    "                               categorical=categorical)\n",
    "        imp_df['run'] = i\n",
    "        actual_imp_df = pd.concat([actual_imp_df, imp_df], axis=0)\n",
    "    \n",
    "    null_imp_df = pd.DataFrame()\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    for i in tqdm(range(num_null_run)):\n",
    "        seed = np.random.randint(1000)\n",
    "        imp_df = _get_lgb_fimp(params,\n",
    "                               X_train,\n",
    "                               y_train,\n",
    "                               features,\n",
    "                               shuffle=True,\n",
    "                               seed=seed,\n",
    "                               categorical=categorical)\n",
    "        imp_df['run'] = i\n",
    "        null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n",
    "    \n",
    "    feature_scores = []\n",
    "    \n",
    "    for _f in actual_imp_df['feature'].unique():\n",
    "        # importance gain of gain\n",
    "        act_fimp_split = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'split'].mean()\n",
    "        null_fimp_split = null_imp_df.loc[null_imp_df['feature'] == _f, 'split'].values\n",
    "        split_score = np.log(eps + act_fimp_split / (1 + np.percentile(null_fimp_split, valid_percentile)))\n",
    "        \n",
    "        # importance gain of gain\n",
    "        act_fimp_gain = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'gain'].mean()\n",
    "        null_fimp_gain = null_imp_df.loc[null_imp_df['feature'] == _f, 'gain'].values\n",
    "        gain_score = np.log(eps + act_fimp_gain / (1 + np.percentile(null_fimp_gain, valid_percentile)))\n",
    "\n",
    "        feature_scores.append((_f, split_score, gain_score))\n",
    "    \n",
    "    scores_df = pd.DataFrame(feature_scores, columns=['feature', 'split_score', 'gain_score'])\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_high_corr_columns(df, threshold=0.99, verbose=True):\n",
    "    df_corr = abs(df.corr())\n",
    "    delete_columns = []\n",
    "    \n",
    "    # diagonal values filled by zero\n",
    "    for i in range(0, len(df_corr.columns)):\n",
    "        df_corr.iloc[i, i] = 0\n",
    "    \n",
    "    # loop as removing high-correlated columns in df_corr\n",
    "    while True:\n",
    "        df_max_column_value = df_corr.max()\n",
    "        max_corr = df_max_column_value.max()\n",
    "        query_column = df_max_column_value.idxmax()\n",
    "        target_column = df_corr[query_column].idxmax()\n",
    "        \n",
    "        if max_corr < threshold:\n",
    "            break\n",
    "        else:\n",
    "            # drop feature which is highly correlated with others \n",
    "            if sum(df_corr[query_column]) <= sum(df_corr[target_column]):\n",
    "                delete_column = target_column\n",
    "                saved_column = query_column\n",
    "            else:\n",
    "                delete_column = query_column\n",
    "                saved_column = target_column\n",
    "            \n",
    "            df_corr.drop([delete_column], axis=0, inplace=True)\n",
    "            df_corr.drop([delete_column], axis=1, inplace=True)\n",
    "            delete_columns.append(delete_column)\n",
    "            \n",
    "            if verbose:\n",
    "                printl('{}: Drop: {} <- Query: {}, Corr: {:.5f}'.format(\n",
    "                    len(delete_columns), delete_column, saved_column, max_corr\n",
    "                ))\n",
    "\n",
    "    return delete_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
