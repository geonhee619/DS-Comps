{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Related (Categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_concat(df, subject_cols, print_option=True):\n",
    "    na_col = list(df.columns[df.isna().any()])\n",
    "    for col in na_col:\n",
    "        df[col].fillna('', inplace=True)\n",
    "    temp_str = ''\n",
    "    for col in subject_cols:\n",
    "        temp_str += '_' + col\n",
    "    df[temp_str[1:]] = ''\n",
    "    for col in subject_cols:\n",
    "        df[temp_str[1:]] += df[col]\n",
    "    \n",
    "    if print_option:\n",
    "        print(\"Generated features: category_concat\")\n",
    "        print(f\"'{temp_str[1:]}',\")\n",
    "        print()\n",
    "    del na_col, temp_str, col; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoder (OOF / smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class apply_target_encode:\n",
    "    \n",
    "    # (for train/train in oof)\n",
    "    # fit grouped label stats of given df\n",
    "    def fit_train(df, target_col, cat_col, m, statistic):\n",
    "        # df[target_col] = np.log1p(df[target_col])\n",
    "        df_group = df.groupby(cat_col)[target_col]\n",
    "        group_mean = df_group.mean().astype(np.float16)\n",
    "        temp_stat = []\n",
    "        # ===== smoothing =====\n",
    "        if m > 0:\n",
    "            global_mean = df[target_col].mean()\n",
    "            group_count = df_group.count().astype(np.float16)\n",
    "            smoother = ((group_count * group_mean) + (m * global_mean)) / (group_count + m)\n",
    "            temp_mean = (smoother, f'SMTH_MEAN_{m}')\n",
    "        # ===== no smoothing =====\n",
    "        elif m == 0:\n",
    "            temp_mean = (group_mean, 'MEAN')\n",
    "        # ===== more target statistic =====\n",
    "        if statistic:\n",
    "            group_min = df_group.min().astype(np.float16)\n",
    "            group_max = df_group.max().astype(np.float16)\n",
    "            group_std = df_group.std().astype(np.float16)\n",
    "            group_rng = group_max - group_min\n",
    "            group_Q1 = df_group.quantile(0.25).astype(np.float16)\n",
    "            group_Q2 = df_group.median().astype(np.float16)\n",
    "            group_Q3 = df_group.quantile(0.75).astype(np.float16)\n",
    "            group_IQR = group_Q3 - group_Q1\n",
    "            temp_stat = [(group_max, 'MAX'), (group_min, 'MIN'),\n",
    "                         (group_rng, 'RNG'), (group_std, 'STD'),\n",
    "                         (group_Q1, 'Q1'), (group_Q2, 'Q2'),\n",
    "                         (group_Q3, 'Q3'), (group_IQR, 'IQR')]\n",
    "        temp_stat.append(temp_mean)\n",
    "        return temp_stat\n",
    "    \n",
    "    # (for train/valid in oof)\n",
    "    # transform (encode) given df via given grouped label stats from fit_train\n",
    "    def transform_valid(temp_stat, df, valid_idx, cat_col, print_option):\n",
    "        for mapper, agg_str in temp_stat:\n",
    "            if fold == 0:\n",
    "                df[f'{cat_col}_{agg_str}'] = 'te_empty'\n",
    "            df.loc[valid_idx, f'{cat_col}_{agg_str}'] = df[cat_col].map(mapper)\n",
    "            if print_option:\n",
    "                print(f\"'{cat_col}_{agg_str}',\")\n",
    "                \n",
    "    # (for test in oof)\n",
    "    # fit_train and tranform_valid combined\n",
    "    def transform_test(df, test_df, target_col, cat_col, m, statistic, print_option):\n",
    "        temp_stat = apply_target_encode.fit_train(df, target_col, cat_col, m, statistic)\n",
    "        for mapper, agg_str in temp_stat:\n",
    "            test_df[f'{cat_col}_{agg_str}'] = test_df[f'{cat_col}'].map(mapper)\n",
    "            if print_option:\n",
    "                print(f\"'{cat_col}_{agg_str}',\")\n",
    "    \n",
    "    # (for ordinary use)\n",
    "    # fit_train and tranform_valid combined\n",
    "    def fit_transform(df, test_df, target_col, cat_col, m=0, statistic=False, print_option=True):\n",
    "        temp_stat = apply_target_encode.fit_train(df, target_col, cat_col, m, statistic)\n",
    "        for mapper, agg_str in temp_stat:\n",
    "            df[f'{cat_col}_{agg_str}'] = df[f'{cat_col}'].map(mapper)\n",
    "            test_df[f'{cat_col}_{agg_str}'] = test_df[f'{cat_col}'].map(mapper)\n",
    "            if print_option:\n",
    "                print(f\"'{cat_col}_{agg_str}',\")\n",
    "    \n",
    "    # train/train: fit grouped label statistic (with fit_train)\n",
    "    # train/valid: encode via the fitted (with transform_valid)\n",
    "    # test: fit with entire train, encode to test\n",
    "    # note: equal m/statistic is applied to all sets\n",
    "    def oof(df, test_df, target_col, cat_col, split, m=0, statistic=False, print_option=True):\n",
    "        # train/valid target encode\n",
    "        for fold, (train_idx, valid_idx) in enumerate(split):\n",
    "            temp_stat = apply_target_encode.fit_train(df=df.loc[train_idx, :],\n",
    "                                                      target_col=target_col, cat_col=cat_col,\n",
    "                                                      m=m, statistic=statistic)\n",
    "            apply_target_encode.transform_valid(temp_stat=temp_stat,\n",
    "                                                df=df, valid_idx=valid_idx, cat_col=cat_col,\n",
    "                                                print_option=False)\n",
    "            if 'te_empty' in df[f'{cat_col}_{agg_str}']:\n",
    "                print(f\"te_empty still left in '{cat_col}_{agg_str}'\")\n",
    "        # test oof (=train) target encode\n",
    "        apply_target_encode.transform_test(df=df, test_df=test_df,\n",
    "                                           target_col=target_col, cat_col=cat_col,\n",
    "                                           m=m, statistic=statistic,\n",
    "                                           print_option=print_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode (not ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_encode(df, test_df, subject_cols):\n",
    "    lbl = LabelEncoder()\n",
    "    for str_col in subject_cols:\n",
    "        lbl.fit(df[str_col].unique())\n",
    "        df[str_col] = lbl.transform(df[str_col])\n",
    "        test_df[str_col] = lbl.transform(test_df[str_col])\n",
    "    del lbl, str_col; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for meta)\n",
    "def apply_label_encode(df, subject_cols):\n",
    "    for str_col in subject_cols:\n",
    "        # ===== assumes Series of string =====\n",
    "        temp_dict = {value: i for i, value in enumerate(df[str_col].unique())}\n",
    "        df[str_col] = (df[str_col].map(temp_dict)).astype(np.int16)\n",
    "    del temp_dict, str_col; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency / Count Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_freq_encode(df, str_col, print_option=True):\n",
    "    temp_dict = {sample: df.loc[df[str_col]==sample].shape[0] for sample in df[str_col].unique()}\n",
    "    df[f'{str_col}_COUNT'] = df[str_col].map(temp_dict)\n",
    "    df[f'{str_col}_RATIO'] = df[str_col].map(temp_dict) / df[str_col].shape[0]\n",
    "    \n",
    "    if print_option:\n",
    "        print(f\"'{str_col}_COUNT',\")\n",
    "        print(f\"'{str_col}_RATIO',\")\n",
    "        print()\n",
    "    del temp_dict; gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
