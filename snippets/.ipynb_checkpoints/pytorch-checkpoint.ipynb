{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数（モデル定義時に必要となるもの）\n",
    "INPUT_FEATURES = 2  # 入力（特徴）の数： 2\n",
    "OUTPUT_NEURONS = 1  # ニューロンの数： 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数（モデル定義時に必要となるもの）\n",
    "activation = torch.nn.Tanh()  # 活性化関数： tanh関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tanh()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「torch.nn.Moduleクラスのサブクラス化」によるモデルの定義\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 層（layer：レイヤー）を定義\n",
    "        self.layer1 = nn.Linear(  # Linearは「全結合層」を指す\n",
    "            INPUT_FEATURES,       # データ（特徴）の入力ユニット数\n",
    "            OUTPUT_NEURONS)       # 出力結果への出力ユニット数\n",
    "\n",
    "    def forward(self, input):\n",
    "        # フィードフォワードを定義\n",
    "        output = activation(self.layer1(input))  # 活性化関数は変数として定義\n",
    "        # 「出力＝活性化関数（第n層（入力））」の形式で記述する。\n",
    "        # 層（layer）を重ねる場合は、同様の記述を続ければよい（第3回）。\n",
    "        # 「出力（output）」は次の層（layer）への「入力（input）」に使う。\n",
    "        # 慣例では入力も出力も「x」と同じ変数名で記述する（よって以下では「x」と書く）\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル（NeuralNetworkクラス）のインスタンス化\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメーター（ニューロンへの入力で必要となるもの）の定義\n",
    "# 重みとバイアスの初期値設定\n",
    "model.layer1.weight = nn.Parameter(torch.tensor([[0.6, -0.2]]))  # 重み\n",
    "model.layer1.bias = nn.Parameter(torch.tensor([0.8]))  # バイアス\n",
    "# modelname.layername.weight/bias = nn.Parameter(torch.tensor[if scalar, [].\n",
    "                                                # elif ndarray such as weight, [[]].])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight', tensor([[ 0.6000, -0.2000]])),\n",
       "             ('layer1.bias', tensor([0.8000]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.Module全体の状態を辞書形式で取得\n",
    "params = model.state_dict()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.6000, -0.2000]], requires_grad=True), Parameter containing:\n",
       " tensor([0.8000], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.]])\n",
      "tensor([[0.7616]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "# feed forward\n",
    "X_data = torch.tensor([[1.0, 2.0]])  # 入力する座標データ（1.0、2.0）\n",
    "print(X_data)\n",
    "# tensor([[1., 2.]]) ……などと表示される\n",
    "\n",
    "y_pred = model(X_data)  # このモデルに、データを入力して、出力を得る（＝予測：predict）\n",
    "print(y_pred)\n",
    "# tensor([[0.7616]], grad_fn=<TanhBackward>) ……などと表示される\n",
    "# grad_dn is the a() used to compute partial deriv for backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "# conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"173pt\" height=\"226pt\"\n",
       " viewBox=\"0.00 0.00 172.50 226.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 222)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-222 168.5,-222 168.5,4 -4,4\"/>\n",
       "<!-- 4777553680 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4777553680</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"123.5,-21 33.5,-21 33.5,0 123.5,0 123.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TanhBackward</text>\n",
       "</g>\n",
       "<!-- 5066867216 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5066867216</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"130.5,-78 26.5,-78 26.5,-57 130.5,-57 130.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 5066867216&#45;&gt;4777553680 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5066867216&#45;&gt;4777553680</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M78.5,-56.7787C78.5,-49.6134 78.5,-39.9517 78.5,-31.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"82.0001,-31.1732 78.5,-21.1732 75.0001,-31.1732 82.0001,-31.1732\"/>\n",
       "</g>\n",
       "<!-- 4777550160 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4777550160</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"69,-148 0,-148 0,-114 69,-114 69,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"34.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">layer1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"34.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n",
       "</g>\n",
       "<!-- 4777550160&#45;&gt;5066867216 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4777550160&#45;&gt;5066867216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46.2912,-113.9832C52.1102,-105.5853 59.1536,-95.4204 65.1681,-86.7404\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"68.1503,-88.5817 70.969,-78.3687 62.3966,-84.5949 68.1503,-88.5817\"/>\n",
       "</g>\n",
       "<!-- 4777551568 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4777551568</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159.5,-141.5 87.5,-141.5 87.5,-120.5 159.5,-120.5 159.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4777551568&#45;&gt;5066867216 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4777551568&#45;&gt;5066867216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M115.8664,-120.2281C109.2973,-110.9585 99.6682,-97.3707 91.8302,-86.3104\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.6585,-84.2481 86.0209,-78.1128 88.9472,-88.2955 94.6585,-84.2481\"/>\n",
       "</g>\n",
       "<!-- 4777550032 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4777550032</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"164.5,-218 82.5,-218 82.5,-184 164.5,-184 164.5,-218\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">layer1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 2)</text>\n",
       "</g>\n",
       "<!-- 4777550032&#45;&gt;4777551568 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4777550032&#45;&gt;4777551568</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M123.5,-183.6966C123.5,-174.0634 123.5,-162.003 123.5,-151.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.0001,-151.7912 123.5,-141.7913 120.0001,-151.7913 127.0001,-151.7912\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1309d0250>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(y_pred, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "青色のボックス： 勾配を計算する必要があるパラメーター（重みやバイアスなど）。\n",
    "　　　　　　 　この例では(1, 2)が重みで、(1)がバイアス\n",
    "灰色のボックス： 勾配（偏微分）などを計算するための関数。\n",
    "　　　　　　 　関数（この例では「TBackward」や「AddmmBackward」）は\n",
    "　　　　　　 　「テンソル」データのgrad_fn属性に自動作成されている\n",
    "緑色のボックス： グラフ計算の開始点。\n",
    "　　　　　　 　backward()メソッド（後述）を呼び出すと、ここから逆順に計算していく。\n",
    "　　　　　　 　内容は灰色のボックスと同じ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# Backprop with AutoGrad (自動微分) via bakckward()\n",
    "# e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let x = 1 (forward feed of x)\n",
    "\n",
    "x = torch.tensor(1.0, requires_grad=True)  # 今回は入力に勾配（gradient）を必要とする\n",
    "# 「requires_grad」が「True」（デフォルト：False）の場合、\n",
    "# torch.autogradが入力テンソルに関するパラメーター操作（勾配）を記録するようになる\n",
    "\n",
    "#x.requires_grad_(True)  # 「requires_grad_()」メソッドで後から変更することも可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# define model. here, y = x**2.\n",
    "# FFの段階では、y = 1**2 = 1となる。\n",
    "\n",
    "y = x ** 2     # 「yイコールxの二乗」という計算式の計算グラフを構築\n",
    "print(y)       # tensor(1., grad_fn=<PowBackward0>) ……などと表示される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backprop. start from output y. in NN, start from final activation (yhat)\n",
    "\n",
    "y.backward()   # 逆伝播の処理として、上記式から微分係数（＝勾配）を計算（自動微分：Autograd）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "g = x.grad     # 与えられた入力（x）によって計算された勾配の値（grad）を取得\n",
    "print(g)       # tensor(2.)  ……などと表示される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output is gradient at x defined at initial feed (=1.0)\n",
    "# dy/dx = 2x = 2(1) = 2\n",
    "\n",
    "# with SGD, this will be used to make a step;\n",
    "# x will be updated from initial feed value;\n",
    "# gradient at x will be updated, then used for another epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2002, -0.4005]])\n",
      "tensor([-0.2002])\n"
     ]
    }
   ],
   "source": [
    "# 勾配計算の前に、各パラメーター（重みやバイアス）の勾配の値（grad）をリセットしておく\n",
    "model.layer1.weight.grad = None      # 重み\n",
    "model.layer1.bias.grad = None        # バイアス\n",
    "#model.zero_grad()                   # これを呼び出しても上記と同じくリセットされる\n",
    "\n",
    "X_data = torch.tensor([[1.0, 2.0]])  # 入力データ（※再掲）\n",
    "y_pred = model(X_data)               # 出力結果（※再掲）\n",
    "y_true = torch.tensor([[1.0]])       # 正解ラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()             # 誤差からの損失を測る「基準」＝損失関数\n",
    "loss = criterion(y_pred, y_true)     # 誤差（出力結果と正解ラベルの差）から損失を取得\n",
    "loss.backward()   # 逆伝播の処理として、勾配を計算（自動微分：Autograd）\n",
    "\n",
    "# 勾配の値（grad）は、各パラメーター（重みやバイアス）から取得できる\n",
    "print(model.layer1.weight.grad) # tensor([[-0.2002, -0.4005]])  ……などと表示される\n",
    "print(model.layer1.bias.grad)   # tensor([-0.2002])  ……などと表示される\n",
    "# ※パラメーターは「list(model.parameters())」で取得することも可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above is one epoch of backprop.\n",
    "# .backward() is applied to loss since"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
